{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train multiple models.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNfbxtIv4LZnFPDT19QWaxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/Automated-Product-Identification_PJS/blob/master/Keras%20Modelle/Train_multiple_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm33xp5KKijU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyCRPwgN9Y8T",
        "colab_type": "text"
      },
      "source": [
        "#Set up Colab and Drive for Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd_Nmme2qOht",
        "colab_type": "code",
        "outputId": "0d28a303-d036-4d71-94db-f38d7525d012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX7MEh9W91i0",
        "colab_type": "code",
        "outputId": "72b2ffa0-d7f2-49d1-8f3e-9630e9a017fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd '/content/gdrive/My Drive/MVP Datensatz/'\n",
        "train_dir = 'Trainingsdatensatz5'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/MVP Datensatz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozlhf6PVMyAe",
        "colab_type": "code",
        "outputId": "aac447ba-6ac4-41f4-8e78-e7c8865a51cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import initializers\n",
        "from keras import applications\n",
        "from keras.applications import *\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5q4wtwZ-51I",
        "colab_type": "text"
      },
      "source": [
        "#Global Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtVxF_GK--ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width = 224\n",
        "img_height = 224\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t07IAipqIano",
        "colab_type": "text"
      },
      "source": [
        "##Augmentations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXMT8JFmI3ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featurewise_center = False\n",
        "samplewise_center = False\n",
        "featurewise_std_normalization = False\n",
        "samplewise_std_normalization = False\n",
        "zca_whitening = False\n",
        "horizontal_flip = False\n",
        "vertical_flip = False\n",
        "\n",
        "brightness_range = None \n",
        "preprocessing_function = None\n",
        "\n",
        "zca_epsilon = 1e-06\n",
        "rotation_range = 3\n",
        "width_shift_range = [-50, 0, +50]\n",
        "height_shift_range = [-50, 0, +50]\n",
        "shear_range = 0.0\n",
        "zoom_range = 0.2\n",
        "channel_shift_range = 0.0\n",
        "cval = 0.0\n",
        "interpolation_order = 1\n",
        "\n",
        "fill_mode = 'nearest'\n",
        "data_format = 'channels_last'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA-uGNR1LREm",
        "colab_type": "text"
      },
      "source": [
        "##Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6MDqsocLol2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_split = 0.4\n",
        "rescale = 1./255\n",
        "batch_s = 40\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULS0U2FjMrYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                          featurewise_center = featurewise_center,\n",
        "                          samplewise_center = samplewise_center,\n",
        "                          featurewise_std_normalization = featurewise_std_normalization,\n",
        "                          samplewise_std_normalization = samplewise_std_normalization,\n",
        "                          zca_whitening = zca_whitening,\n",
        "                          zca_epsilon = zca_epsilon,\n",
        "                          rotation_range = rotation_range,\n",
        "                          width_shift_range = width_shift_range,\n",
        "                          height_shift_range = height_shift_range,\n",
        "                          brightness_range = brightness_range,\n",
        "                          shear_range = shear_range,\n",
        "                          zoom_range = zoom_range,\n",
        "                          channel_shift_range = channel_shift_range,\n",
        "                          fill_mode = fill_mode,\n",
        "                          cval = cval,\n",
        "                          horizontal_flip = horizontal_flip,\n",
        "                          vertical_flip = vertical_flip,\n",
        "                          preprocessing_function = preprocessing_function,\n",
        "                          data_format = data_format,\n",
        "                          validation_split = validation_split,\n",
        "                          interpolation_order = interpolation_order,\n",
        "                          rescale = rescale,\n",
        "                          dtype = 'float32'\n",
        "                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqG73Dc1_cXW",
        "colab_type": "code",
        "outputId": "6bd770b6-e7e9-4503-a48d-0a8606ae2d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_set = train_datagen.flow_from_directory(\n",
        "                          train_dir, \n",
        "                          target_size = (img_width,img_height),\n",
        "                          batch_size = batch_s,\n",
        "                          class_mode = 'categorical',\n",
        "                          subset = 'training'\n",
        "                          )\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 84 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3mDhTtf_Uao",
        "colab_type": "code",
        "outputId": "ff012a53-dd1c-4d94-d409-84a7cefcaab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "validation_set = train_datagen.flow_from_directory(\n",
        "                          train_dir, \n",
        "                          target_size = (img_width,img_height),\n",
        "                          batch_size = batch_s,\n",
        "                          class_mode = 'categorical',\n",
        "                          subset = 'validation'\n",
        "                          )\n",
        "       "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 54 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRQGGXC-lPO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Create Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ecKLe_Y5_l",
        "colab_type": "text"
      },
      "source": [
        "#Select and download different pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Ku0wBmOfAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "ffe9084f-2b8b-4ec7-cc5d-03dd2e40c4a9"
      },
      "source": [
        "base_models = [\n",
        "                VGG19(\n",
        "                weights = 'imagenet',\n",
        "                include_top = False,\n",
        "                input_shape = (img_width,img_height,3) \n",
        "              ),\n",
        "                MobileNet(\n",
        "                    weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "              Xception(\n",
        "                    weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "               applications.MobileNetV2(\n",
        "                   weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)\n",
        "               ),\n",
        "               applications.NASNetMobile(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "               applications.VGG16(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "               applications.ResNet152V2(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "               applications.ResNet101V2(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3)),\n",
        "               applications.DenseNet121(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(img_width,img_height,3))\n",
        "               \n",
        "    ]\n",
        "\n",
        "\n",
        "#specifing optimizer and epochs\n",
        "opt = optimizers.RMSprop(learning_rate=0.0005)\n",
        "\n",
        "#evtl. erweiterung für verschiedene optimizer\n",
        "opts = [optimizers.RMSprop(learning_rate=0.0005),\n",
        "        optimizers.Adam]\n",
        "\n",
        "epochs = 1500\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 24s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5\n",
            "19996672/19993432 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 6s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171319296/171317808 [==============================] - 4s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLfGlvxtVst-",
        "colab_type": "text"
      },
      "source": [
        "#Function for initializing and training and saving multiple models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COBARRoEzkPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_models():\n",
        "  i = 0\n",
        "  multiple_models = []\n",
        "  for base_model in base_models:\n",
        "      model = models.Sequential()\n",
        "      model.add(base_model)\n",
        "      model.add(layers.Flatten())\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Dense(256, activation = 'relu', kernel_initializer = initializers.RandomNormal(stddev = 0.01), bias_initializer = initializers.Zeros()))\n",
        "      model.add(layers.Dense(5, activation = 'softmax', kernel_initializer = initializers.RandomNormal(stddev = 0.01), bias_initializer = initializers.Zeros()))\n",
        "      for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "      model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "      multiple_models = model.fit_generator(\n",
        "                    train_set,\n",
        "                    epochs = epochs,\n",
        "                    validation_data = validation_set\n",
        "                    )\n",
        "      model.save(\"/content/gdrive/My Drive/Keras Models/\" + base_model.name + '.h5')\n",
        "      \n",
        "      \n",
        "\n",
        "  return multiple_models\n",
        "      \n",
        "      #model.save(\"/content/gdrive/My Drive/Keras Models/\" + str(base_model.name()))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91jkA2N-VzGD",
        "colab_type": "text"
      },
      "source": [
        "#Function Call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQndws9aPrLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "d40d68cf-45ca-4790-dbb6-dc76d53eccb4"
      },
      "source": [
        "build_models()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "3/3 [==============================] - 31s 10s/step - loss: 1.7538 - acc: 0.2500 - val_loss: 1.9529 - val_acc: 0.2037\n",
            "Epoch 2/1500\n",
            "3/3 [==============================] - 2s 696ms/step - loss: 1.7893 - acc: 0.1667 - val_loss: 1.6944 - val_acc: 0.1852\n",
            "Epoch 3/1500\n",
            "3/3 [==============================] - 3s 865ms/step - loss: 1.7287 - acc: 0.1786 - val_loss: 1.6381 - val_acc: 0.2407\n",
            "Epoch 4/1500\n",
            "3/3 [==============================] - 2s 819ms/step - loss: 1.6312 - acc: 0.2381 - val_loss: 1.4838 - val_acc: 0.1852\n",
            "Epoch 5/1500\n",
            "3/3 [==============================] - 3s 834ms/step - loss: 1.7305 - acc: 0.2143 - val_loss: 1.6869 - val_acc: 0.2222\n",
            "Epoch 6/1500\n",
            "1/3 [=========>....................] - ETA: 2s - loss: 1.5642 - acc: 0.2250"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}