{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception PJS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORKQ2J1lyQ2FKqYx0+BrQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/Automated-Product-Identification_PJS/blob/master/keras_Xception_PJS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOqHQpDHLef7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd_Nmme2qOht",
        "colab_type": "code",
        "outputId": "77f197ba-d512-4f84-9695-d1bd5e5ce6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozlhf6PVMyAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "base_dir = r'/content/gdrive/My Drive/MVP Datensatz/'\n",
        "train_dir = r'/content/gdrive/My Drive/MVP Datensatz/Trainingsdatensatz5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbvFysLQLra6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#Beispiel für mögliche Data Augmentations\n",
        "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                          samplewise_center=False,\n",
        "                          featurewise_std_normalization=False,\n",
        "                          samplewise_std_normalization=False,\n",
        "                          zca_whitening=False,\n",
        "                          zca_epsilon=1e-06,\n",
        "                          rotation_range=3,\n",
        "                          width_shift_range=[-1, 0, +1],\n",
        "                          height_shift_range=[-1, 0, +1],\n",
        "                          brightness_range=None, \n",
        "                          shear_range=0.1, \n",
        "                          zoom_range=0.2,\n",
        "                          channel_shift_range=0.0, \n",
        "                          fill_mode='nearest', \n",
        "                          cval=0.0,\n",
        "                          horizontal_flip=False, \n",
        "                          vertical_flip=False, \n",
        "                          rescale=1./255, \n",
        "                          preprocessing_function=None, \n",
        "                          data_format='channels_last', \n",
        "                          validation_split=0.2, \n",
        "                          interpolation_order=1, \n",
        "                          dtype='float32')\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "                          rescale=1./255,\n",
        "                          validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULS0U2FjMrYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.applications import Xception\n",
        "base_model = Xception(weights='imagenet',\n",
        "  include_top=False,\n",
        "  input_shape=(150,150,3))\n",
        "\n",
        "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "batch_size = 10\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWeSUmygMACb",
        "colab_type": "code",
        "outputId": "9c8d98ab-87e6-40ba-a71e-3b58adc07753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "      \n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "  features = np.zeros(shape=(sample_count, 4, 4, 512)) \n",
        "  labels = np.zeros(shape=(sample_count))\n",
        "  generator = datagen.flow_from_directory(\n",
        "    directory,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "  i=0\n",
        "  for inputs_batch, labels_batch in generator:\n",
        "    features_batch = base_model.predict(inputs_batch)\n",
        "    features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "    labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= sample_count:\n",
        "      break\n",
        "    return features, labels\n",
        "train_features, train_labels = extract_features(train_dir, 100)\n",
        "#validation_features, validation_labels = extract_features(validation_dir, 303)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-194696e7175f>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZjBp6rHL0fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0AovFKyJxEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer for 5 classes\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "    # compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.fit_generator(train_generator,  \n",
        "  steps_per_epoch=139,\n",
        "  epochs=11,\n",
        "  validation_data = validation_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}